% Traçage des connaissances\newline et optimisation de l'apprentissage humain
% Jill-Jênn Vie
% 13 juin 2023
---
handout: true
aspectratio: 169
institute: \includegraphics[height=1cm]{figures/inria.png} \quad \includegraphics[height=2cm]{figures/brest.jpg} \quad \includegraphics[height=1cm]{figures/soda.png}
header-includes:
  - \usepackage{booktabs}
---

# Attention

Les articles que vous allez voir comportent des défauts.

\alert{Reproduisez-les} chez vous et ne les refaites pas à l'avenir.

# Traçage de connaissances (*knowledge tracing*)

On observe des essais d'étudiants sur des exercices (ex. maths avec ASSISTments)

\centering
\begin{tabular}{cccc} \toprule
Items & 5 -- 5 = ? & 17 -- 3 = ? & 13 -- 7 = ?\\ \midrule
New student & \alert{$\circ$} & \alert{$\circ$} & \alert{$\mathbf{\times}$}\\ \bottomrule
\end{tabular}

\raggedright
Apprentissage d'une langue (jeu de données de Duolingo)

\includegraphics{figures/duolingo0.png}

## Challenges

- Les gens peuvent faire des erreurs d'inattention
- Les connaissances évoluent au cours du temps
- Biais des données manquantes (mesurer la persévérance)

<!--

# Combiner modèles discrets et Rasch

Poser la question qui maximise
le nombre moyen d'acquis validés ou invalidés :

\centering

$\textnormal{Maximiser } p(succès) N_{validés} + (1 - p(succès)) N_{invalidés}$

![](figures/example.pdf)

\raggedright

Le code de Pix, en JavaScript, est ouvert (AGPLv3) sur GitHub

\small
\fullcite{Vie2017PIX} -->

# Visuellement : le traçage de connaissances

\includegraphics[width=\linewidth]{figures/dkt.png}

- Couleurs : composantes de connaissances (des savoir-faire)
- Disques : résultats d'apprenants sur ces composantes
- On souhaite généraliser les connaissances à d'autres composantes
    - De bleu à vert : faible à haute probabilité de répondre correctement
- Les apprenants peuvent faire plusieurs essais

## Méthode

Apprendre des paramètres de questions sur des données d'historiques \hfill \emph{ex. difficulté}  
Mesurer les paramètres de nouveaux apprenants \hfill \emph{ex. expertise}  

# Évaluation par validation croisée (jeu de données réel existant)

\centering

![](figures/crossval.pdf)

\raggedright

Métrique de classification : AUC (aire sous la courbe ROC, *receiver operator characteristic*, courbe sensibilité/spécificité, compromis taux de vrais positifs et taux de faux positifs)

# Deep Knowledge Tracing (NIPS 2015)

8+5 pages, 4 figures :  
1 page related, 1 page modèle, 1 page appli, 1 page exp, 2 pages résultats

## Points forts

- Article très clair et facile à lire
- Va beaucoup plus loin que les modèles existants
    - N'a besoin de quasiment rien d'autre que les données brutes  
(pas de représentation du domaine, à part peut-être q-matrice)
- A fortement influencé la communauté (1000 citations depuis 2015)
- Code et la plupart des données disponibles (2 sur 3 datasets)

\pause

## Points faibles

> - Code disponible mais en Lua
> - Trop sophistiqué pour pas grand-chose finalement (on l'a su plus tard)
> - Pas d'expérience sur des vrais humains, juste exécution d'un code sur des données hors ligne
> - En fait : une \alert{grosse erreur} dans les expériences  
(remarquée grâce au fait que le code est ouvert)

# NeurIPS et conférences en apprentissage statistique

## Points forts

- Papiers en open access
- arXiv : sources en open access
- Code souvent open source sous licence libre
- Reviews en open access (anonymisées)
- Il faut avoir réfléchi à l'impact, aux conséquences de la technologie présentée dans le papier
- Interdit de soumettre des articles "ayant une partie conséquente écrite par ChatGPT"

## Point faible

- 12600 papiers soumis en 2023 ! 25 % seront acceptés ?!

# Plus un joli plot (non reproductible : données privées de Khan Academy)

![](figures/conceptClusters.pdf)

# Modèles graphiques pour le traçage de connaissances

![](figures/hmm.png)

- Bayesian Knowledge Tracing est un modèle de Markov caché (Corbett and Anderson, 1994)
- Deep Knowledge Tracing est un réseau de neurones récurrent (Piech et al. 2015)

# Résultats

\begin{table}\centering
\begin{tabular}{@{}llllcllll@{}}
\toprule
& \multicolumn{3}{c}{$Overview$} & \phantom{abc} &
 \multicolumn{4}{c}{$AUC$} \\
\cmidrule{2-4} 
\cmidrule{6-9}  
Dataset & Students & Exercise Tags & Answers && Marginal & BKT & BKT* & DKT \\ 
\midrule
Simulated-5 & 4,000 & 50 & 200 K && 0.64 & 0.54 & - & 0.82 \\
Khan Math  & 47,495 & 69 & 1,435 K && 0.63 & 0.68 & - & 0.85 \\
% Bridge to Algebra & 3,310 & 1,829 & 8,918,000 && ? & ? & ? \\
Assistments & 15,931 & 124 & 526 K && 0.62 & 0.67 & 0.69 & 0.86 \\
\bottomrule
\end{tabular}
\caption{AUC results for all datasets tested. BKT is the standard BKT. BKT* is the best reported result from the literature for Assistments. DKT is the result of using LSTM Deep Knowledge Tracing.
% Note that the best performing models in Bridge to Algebra make use of student performance {\em after} as well as before the test set, while DKT restricts itself to a causal prediction of student performance.
\label{table:results}
}
\vspace{-3mm}
\end{table}

# Tuteurs intelligents : apprendre une politique pour poser les questions

\centering

![](figures/asking.pdf)

\raggedright

- Soit on a un simulateur (ex. un modèle de traçage des connaissances) et on fait les expériences (virtuelles) qu'on veut (apprentissage par renforcement en ligne) \hfill $\to$ problème, tout modèle est imparfait
- Soit on a strictement les données réelles $\to$ apprentissage par renforcement hors ligne (offline RL) $\to$ estimateurs à forte variance
- Soit on une cohorte observée (distinction entre deux groupes)
- Soit on a un test randomisé contrôlé

# 

![](figures/rct.png)

Source: https://quantifyinghealth.com/cohort-vs-randomized-controlled-trials/

# Système de tuteurs intelligent

Exemple : apprendre à des jeunes à compter avec une interface ludique

![](figures/exMbis.png)

# Multi-Armed Bandits for Intelligent Tutoring Systems (JEDM 2015)

21+8 pages, 9 figures :  
1 page related, 7 pages modèles, 9 pages exp (4 simulés, 5 réels)

But : deux algorithmes pour sélectionner l'activité suivante de façon plus personnalisée qu'un algorithme expert

## Points forts

- A influencé la communauté (100 citations depuis 2015)
- Beaucoup de discussion des résultats (les avantages d'un papier journal)
- Expérience sur des étudiants simulés **et** sur 400 étudiants de 7 à 8 ans (l'un des coauteurs, Didier Roy, est un ancien prof de maths) $\to$ de nos jours, comité d'éthique
- Déployé dans des vrais projets dans des vraies classes (Adaptiv'Math, P2IA)
- Essai randomisé contrôlé + tests statistiques + beaucoup de résultats
    - Chacune des classes des 11 écoles divisée en 4 groupes :  
algorithme expert (prof) / Algo A / Algo B / groupe contrôle

# Multi-Armed Bandits for Intelligent Tutoring Systems (JEDM 2015)

## Points faibles

> - Code open source puis \alert{supprimé} par les auteurs !!! (heureusement il en existe encore un fork, vive GitHub)
> - Algo 2 repose sur une représentation du domaine coûteuse à construire
    - À la fois un algo de machine learning à la fois la construction d'une représentation du domaine coûteuse pour l'expert
> - Fait le choix délibéré d'ignorer la littérature existante (et réinvente plusieurs trucs sans les nommer)
    - Balaie d'un revers de main des années de recherche sur les bandits pour prendre le modèle le plus simple de bandit possible "we rely on SOTA multi-arm bandit techniques" $\to$ tut tut tut
> - Notations difficiles à suivre, beaucoup d'acronymes
> - Pre-tests et post-tests sont faits avec le même outil

# Besoin d'une représentation du domaine

De l'intérêt d'une personnalisation contrôlée

![](figures/ZPDESgraph.png)

# En pratique, les pauvres profs pour Algo B

![](figures/qmatrix1.png) ![](figures/qmatrix2.png)

# Un mot sur les bandits

![](figures/ucb.jpg)

\alert{Compromis entre exploitation} (machines qui marchent)  
et \alert{exploration} (peut-être d'autres machines peu testées)

\tiny

Source : \url{https://eugeneyan.com/writing/bandits/}

# Un mot sur l'apprentissage par renforcement : quelle récompense choisir ?

## Optimisation de l'apprentissage humain

\alert{Maximiser l'information à chaque question} $\rightarrow$ les apprenant·es échouent 50 % du temps  
(bien pour l'évaluateur, pas pour les apprenant·es) \bigskip

\pause

\alert{Maximiser le taux de succès} $\rightarrow$ on pose artificiellement des questions trop simples \bigskip

\pause

\alert{Identifier une lacune de l'apprenant·e le plus vite possible} (Teng et al., ICDM 2018) ou Rotting bandits are not harder than stochastic ones (Seznec et al., AISTATS 2019) \bigskip

\pause

\alert{Maximiser l'accroissement du taux de succès} Multi-Armed Bandits for Intelligent Tutoring Systems (Clement et al., JEDM 2015)

# Résultat de l'essai randomisé contrôlé

:::::: {.columns}
::: {.column width=50%}
## Contrôle
![](figures/testRes_cumul_Control.png)
:::
::: {.column width=50%}
## Traitement
![](figures/testRes_cumul_Normal.png)
:::
:::

# Take home message

## Psychométrie

Données simulées OK, parfois avec données réelles

## Educational Data Mining

Données réelles, de plus en plus demande d'études même petites sur des vrais apprenants

## Conférences de machine learning

- Théorie, ou application avec données réelles
- Peu d'études sur des vrais utilisateurs
- Maximum de reproductibilité

# À propos des papiers

Il n'existe pas de papier exemplaire

\begin{thebibliography}{1}
\setbeamertemplate{bibliography item}[article]
\bibitem{C} Chris Piech et al. “Deep knowledge tracing”. In: Advances in Neural Information
Processing Systems (NIPS). 2015, pp. 505–513.
\end{thebibliography}

Bien écrit et comporte des erreurs dans les expériences mais a quand même profondément inspiré le domaine

\begin{thebibliography}{1}
\setbeamertemplate{bibliography item}[book]
\bibitem{B} Benjamin Clément et al. “Multi-Armed Bandits for Intelligent Tutoring Systems”.
In: Journal of Educational Data Mining 7.2 (2015), pp. 20–48.
\end{thebibliography}

Difficile à lire mais a le mérite d'avoir été testé / prouvé sur des vrais étudiants

On parle souvent de compromis entre interprétabilité et performance, je pense qu'il vaut surtout parler de compromis \alert{adaptabilité et contrôle}

Merci pour votre attention !
